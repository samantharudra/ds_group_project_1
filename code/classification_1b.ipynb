{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4eb6c910-f6dc-4043-a5a1-9d3af7d09a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dccb8807-524a-4a1a-beb8-ea8bd9b2949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in preprocessed data\n",
    "data = pd.read_csv(\"../data/preprocessed/preprocessed_crime_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab0806-5a62-47fc-a77c-80c81db91b7f",
   "metadata": {},
   "source": [
    "### Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923a960f-407e-4029-93eb-a8b89d02357e",
   "metadata": {},
   "source": [
    "The initial goal is to predict `ViolentCrimesPerPop` which is a continuous variable. Given the complexity of the datset, a Linear Regression model is a good starting point. However, because there are likely correlated features and potential multicollinearity, regularization methods like Ridge or Lasso are more suitable. \n",
    "\n",
    "- Ridge: Linear model that penalizes large coefficients using L2 regularization, reducing the impact of multicollinearity.\n",
    "\n",
    "- Lasso: Uses L1 regularization and may lead to feature selection, which may be useful if we suspect some irrelevant features (likely since the dataset is so large).\n",
    "\n",
    "We will implement both and evaluate to select the best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9b10c-1c4b-4069-8318-5a4b9ad4d7a8",
   "metadata": {},
   "source": [
    "### Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51b0ce79-7688-485a-bb5d-019700c5cab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1009.000000\n",
       "mean        0.177017\n",
       "std         0.162876\n",
       "min         0.000000\n",
       "25%         0.060000\n",
       "50%         0.120000\n",
       "75%         0.230000\n",
       "max         0.910000\n",
       "Name: ViolentCrimesPerPop, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics for target column \n",
    "data['ViolentCrimesPerPop'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c536d-4e86-4e3b-af92-e4a749337901",
   "metadata": {},
   "source": [
    "We will first discreticize the target variable `ViolentCrimesPerPop` to convert it into a categorical variable suitable for a classification task. To convert it into a binary classification problem, we need to set a threshold. The idea behind this process is to create an algorithm to predict communities with significant crime rates. An algorithm that is able to identify communities at high risk for crime could be used in a variety of policy contexts, including knowing where to increase police presence or have other targeted interventions in specific communities. \n",
    "\n",
    "For the binary variable, we will create an indicator for whether the `ViolentCrimesPerPop` falls above a threshold. We will define 1 as communities with significant crime, those falling above the 75th percentile. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909b913-f1ec-4fa3-bfd4-15b8f90f41de",
   "metadata": {},
   "source": [
    "#### Discretization & Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c37b236-2e7d-49af-bb8a-325f015e6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set threshold \n",
    "threshold = data['ViolentCrimesPerPop'].quantile(0.75)\n",
    "\n",
    "# create target variable \n",
    "data['target'] = (data['ViolentCrimesPerPop'] > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5029e18-1a9f-44b6-91f2-315639de4861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    759\n",
       "1    250\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74412148-9076-42f1-9891-be5a0349b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# split using stratification \n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=7)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c00570-00dd-4a2e-87e2-d3d566a5ba21",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2ae5b-2206-4e8d-8547-b4c3b9c251d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
